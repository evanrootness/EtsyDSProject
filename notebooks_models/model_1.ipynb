{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/evanrootness/DS_Projects/EtsyDSProject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/Users/evanrootness/DS_Projects/EtsyDSProject\")\n",
    "pwd = os.getcwd()\n",
    "print(pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import scipy.optimize as opt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(pwd + '/data/cleaned_data.csv', )\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, xtest, y_train, ytest = train_test_split(data.iloc[:, 5:], \n",
    "                                                  data.iloc[:, 1], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([3.0000e+01, 1.9800e+01, 1.0000e+00, 1.0640e+01, 1.1000e+02,\n       2.1000e+01, 2.9500e+00, 2.4060e+01, 2.0000e+00, 4.0800e+00,\n       1.0000e+02, 2.2000e+01, 8.0000e+01, 9.9800e+00, 6.0000e+00,\n       5.7310e+01, 4.5000e+00, 4.9500e+02, 3.5518e+02, 2.5000e+01,\n       1.9000e+01, 1.0243e+02, 8.2000e+01, 7.9750e+01, 4.8000e+00,\n       7.9800e+00, 1.0640e+01, 5.9000e+01, 1.3500e+02, 1.6500e+01,\n       8.0200e+00, 2.4000e+01, 2.8080e+01, 4.2200e+00, 1.0310e+01,\n       4.2200e+00, 5.7200e+00, 8.9400e+00, 3.2500e+02, 2.4000e+01,\n       2.7410e+01, 5.6940e+01, 2.9930e+01, 4.8000e+00, 3.6000e+02,\n       1.8330e+01, 4.6600e+00, 4.1100e+00, 3.4600e+00, 2.2500e+01,\n       4.7900e+00, 2.2000e+02, 8.9100e+00, 1.8000e+01, 8.0000e+00,\n       2.2550e+01, 3.0000e+01, 1.5960e+01, 1.0510e+01, 1.7190e+01,\n       1.0540e+01, 2.2500e+01, 5.2720e+01, 2.6610e+01, 5.8000e+00,\n       1.8000e-01, 2.7000e+01, 2.6610e+01, 1.7000e+01, 3.1930e+01,\n       3.1930e+01, 1.0000e+02, 3.0000e+01, 3.0000e+01, 1.2000e+02,\n       8.2500e+00, 2.7000e+01, 2.9500e+01, 6.2700e+00, 1.9000e+01,\n       1.4300e+02, 1.4220e+02, 4.2000e+00, 4.2000e+00, 4.2200e+00,\n       3.0000e+01, 6.5000e+01, 7.5000e+01, 8.1000e+01, 5.4000e+01,\n       1.5000e+02, 2.1550e+01, 9.8100e+01, 4.2890e+01, 1.8000e+03,\n       7.0000e+02, 1.3250e+01, 5.3210e+01, 9.6410e+02, 3.4190e+01,\n       2.2550e+01, 3.7250e+01, 6.0000e+00, 1.9955e+02, 3.0000e+01,\n       4.9950e+01, 5.0060e+01, 5.7300e+00, 3.0000e+01, 8.0200e+00,\n       3.5110e+01, 9.2400e+00, 6.0000e+00, 5.5000e+01, 8.0200e+00,\n       1.3137e+02, 1.4000e+01, 2.9900e+00, 1.1340e+01, 2.5000e+01,\n       2.6610e+01, 2.5000e+01, 8.5000e+01, 4.0490e+01, 2.2500e+01,\n       8.2500e+00, 5.5700e+00, 4.9950e+01, 8.2500e+00, 3.4370e+01,\n       1.0500e+02, 3.4000e+01, 1.5000e+00, 6.9000e+01, 2.1550e+01,\n       4.0490e+01, 9.7400e+00, 4.6530e+01, 1.3600e+01, 2.2550e+01,\n       1.5000e+01, 2.5000e+01, 2.0620e+01, 5.8000e+01, 2.3000e+01,\n       1.0630e+01, 2.5280e+01, 1.5300e+02, 1.1970e+01, 1.1970e+01,\n       2.5000e+01, 3.4950e+01, 1.9602e+02, 5.5000e+01, 3.1930e+01,\n       4.5000e+01, 1.5680e+01, 2.0000e+00, 2.5000e+01, 1.5000e+01,\n       4.6500e+01, 5.0000e+00, 2.8080e+01, 6.8700e+00, 1.0460e+01,\n       3.6000e+01, 5.3200e+00, 1.9500e+01, 9.8000e+01, 3.2000e-01,\n       2.6000e+01, 9.9900e+00, 1.2000e+03, 3.2000e+01, 3.4000e+01,\n       4.0000e+01, 3.0000e+02, 1.0000e+00, 1.3300e+01, 2.5420e+01,\n       3.9022e+02, 3.0000e+01, 1.5000e+01, 1.0510e+01, 1.3000e+01,\n       8.0000e+00, 2.1290e+01, 6.8700e+00, 6.0000e+00, 6.2700e+00,\n       1.8000e+01, 4.8100e+00, 1.1000e+02, 1.3600e+01, 5.5000e+01,\n       2.0620e+01, 4.5000e+01, 2.2500e+02, 4.1100e+00, 3.0000e+01,\n       4.1250e+01, 1.0500e+02, 1.9000e+01, 8.0200e+00, 4.2200e+00,\n       4.9900e+00, 5.3210e+01, 9.0000e-01, 5.1220e+01, 2.8080e+01,\n       6.0000e+02, 2.9320e+01, 5.9900e+00, 5.9100e+00, 1.7160e+01,\n       3.3260e+01, 4.3200e+00, 3.9000e+00, 3.0000e+01, 1.0500e+02,\n       3.8730e+01, 5.5000e+01, 7.8000e+01, 1.0000e+01, 7.9500e+00,\n       3.0000e+01, 1.1970e+01, 3.7570e+01, 1.1999e+02, 2.2100e+02,\n       1.9950e+01, 8.0000e+00, 6.0000e+01, 2.7910e+01, 1.0040e+01,\n       2.0000e+00, 4.2200e+00, 3.0000e+02, 1.5000e+01, 1.8000e+01,\n       6.0000e+00, 2.1550e+01, 1.5000e+01, 7.0000e+02, 8.9400e+00,\n       6.0000e+00, 3.4000e+01, 3.2930e+01, 1.8620e+01, 1.0000e+01,\n       2.5950e+01, 5.4900e+00, 1.6000e+01, 9.4900e+00, 5.6700e+00,\n       4.4980e+01, 6.0000e+00, 1.0950e+01, 5.5000e+01, 4.2200e+00,\n       1.5000e+02, 4.2200e+00, 2.9500e+00, 1.9000e+01, 3.2070e+01,\n       8.0000e+00, 1.8000e+01, 5.3600e+00, 1.6500e+01, 1.8000e+01,\n       4.8800e+00, 1.6500e+02, 5.2720e+01, 2.0000e+01, 1.6870e+01,\n       7.9900e+00, 5.5000e+01, 3.8000e+01, 8.0200e+00, 1.9950e+01,\n       3.9000e+01, 5.4900e+00, 1.5000e+00, 8.7300e+00, 4.8000e+01,\n       1.8030e+01, 1.9950e+01, 1.6960e+01, 4.3500e+02, 1.0000e+01,\n       4.2200e+00, 6.0000e+00, 3.4000e+01, 2.1550e+01, 8.2500e+00,\n       3.5000e+01, 2.1220e+01, 5.1880e+01, 6.1870e+01, 1.5950e+01,\n       4.7800e+02, 2.4000e+01, 4.9950e+01, 4.6560e+01, 1.8000e+03,\n       3.3230e+01, 6.0000e+02, 2.0000e+01, 2.4000e+01, 1.2500e+00,\n       1.5960e+01, 2.6610e+01, 2.0000e+00, 5.8000e+00, 3.5140e+01,\n       8.0000e+00, 2.6000e+01, 1.1970e+01, 8.0000e+00, 4.2200e+00,\n       3.8000e+01, 1.8000e+01, 1.0640e+01, 1.8330e+01, 4.5000e+01,\n       8.0000e+00, 1.8000e+03, 1.9990e+01, 1.5000e+01, 1.4000e+01,\n       2.0000e+00, 1.7000e+01, 7.2000e+00, 2.0000e+00, 4.9200e+00,\n       4.2200e+00, 3.4600e+00, 8.9400e+00, 3.6000e+01, 3.0000e+01,\n       2.8000e+01, 2.3400e+00, 4.9900e+00, 9.3000e+01, 2.2000e+01,\n       2.2550e+01, 4.0000e+01, 7.1500e+01, 2.9000e+00, 2.3300e+00,\n       2.9700e+00, 2.0000e+01, 2.7500e+01, 3.3260e+01, 6.8970e+01,\n       2.3000e+01, 1.6000e+02, 1.5000e+00, 5.8000e+00, 4.8200e+01,\n       8.5000e+01, 2.8000e+01, 4.0000e+01, 1.8000e+03, 1.7190e+01,\n       4.9900e+00, 2.1000e+02, 1.8000e+02, 2.8990e+01, 1.3000e+02,\n       6.9900e+00, 8.0200e+01, 6.1900e+00, 3.0000e+01, 1.4300e+02,\n       1.0000e+02, 1.8000e+03, 4.9500e+01, 1.1300e+01, 3.5000e+01,\n       3.4000e+01, 2.3000e+01, 1.8000e+01, 2.0000e+00, 1.3600e+01,\n       1.4000e+01, 1.2000e+01, 3.0000e+01, 3.9200e+01, 5.5884e+02,\n       3.5250e+01, 4.5000e+01, 5.4500e+00, 1.0640e+01, 2.6610e+01,\n       1.8030e+01, 3.5000e+01, 5.2700e+01, 4.0000e+00, 3.3260e+01,\n       3.9990e+01, 1.9000e+01, 1.8000e+01, 7.2000e+01, 2.4610e+01,\n       7.9750e+01, 2.7000e+00, 2.5000e+01, 5.0000e+00, 3.8700e+00,\n       2.1220e+01, 1.2130e+01, 4.9390e+01, 1.0640e+01, 5.2300e+00,\n       1.9000e+01, 1.9000e+01, 3.2300e+01, 2.9400e+01, 2.0000e+01,\n       5.7310e+01, 1.0500e+02, 1.3600e+01, 5.0000e+00, 2.6610e+01,\n       7.9750e+01, 3.3230e+01, 2.5000e+01, 6.6900e+00, 5.2000e+01,\n       5.9000e+01, 4.0000e+01, 3.3260e+01, 3.7200e+00, 3.2000e-01,\n       6.0000e+01, 8.9500e+00, 7.9100e+00, 2.8000e+01, 4.5000e+01,\n       2.4990e+01, 1.0505e+02, 2.2500e+00, 4.7760e+01, 1.6230e+01,\n       3.3230e+01, 2.2900e+00, 4.2570e+01, 4.2200e+00, 2.2610e+01,\n       4.6000e+01, 1.2470e+01, 5.7300e+00, 3.2000e-01, 1.0641e+02,\n       3.9990e+01, 1.6000e+01, 5.8000e+00, 8.0250e+01, 2.0250e+01,\n       1.0000e+01, 2.1000e+01, 1.2000e+01, 1.7600e+01, 1.6500e+01,\n       2.3940e+01, 2.3000e+01, 2.0000e+00, 4.9900e+00, 5.0000e+00,\n       1.6480e+01, 5.2720e+01, 8.0000e+00, 1.5000e+01, 5.6140e+01,\n       3.6660e+01, 2.1550e+01, 3.2000e+01, 4.2200e+00, 5.6140e+01,\n       6.1250e+01, 6.5000e+01, 1.9990e+01, 3.2000e+01, 1.6000e+03,\n       1.1369e+02, 1.7960e+01, 9.6000e+01, 2.1500e+01, 5.3200e+00,\n       6.0000e+00, 3.9910e+01, 4.0000e+00, 2.3400e+00, 8.0000e+00,\n       1.0000e+00, 2.2620e+01, 8.2490e+01, 1.0000e+00, 1.7150e+01,\n       5.0000e+01, 7.0000e+00, 3.3260e+01, 4.5000e+01, 1.6000e+01,\n       3.2000e+01, 5.8500e+02, 3.3230e+01, 4.9950e+01, 3.5400e+00,\n       1.8000e+01, 5.3200e+00, 5.5000e+01, 2.2610e+01, 2.1550e+01,\n       1.0000e+01, 1.4450e+01, 2.7940e+01, 1.9950e+01, 4.1100e+00,\n       2.6610e+01, 3.8250e+01, 5.0000e+00, 1.6000e+01, 2.3000e+01,\n       1.0640e+01, 2.5000e+01, 1.5000e+02, 2.6610e+01, 2.0620e+01,\n       9.4900e+00, 1.7000e+03, 2.8990e+01, 8.5000e+01, 2.4610e+01,\n       3.4230e+01, 4.2200e+00, 1.3000e+01, 7.7300e+00, 1.8000e+01,\n       6.0000e+00, 1.9000e+01, 2.0000e+00, 1.5990e+01, 3.3112e+02,\n       7.9800e+00, 4.8000e+01, 2.2620e+01, 2.2500e+00, 1.5300e+02,\n       2.5000e+01, 9.9770e+01, 1.4630e+01, 2.3280e+01, 1.1760e+01,\n       2.0000e+01, 3.3260e+01, 1.7000e+03, 6.5000e+02, 3.7570e+01,\n       3.0900e+00, 4.2200e+00, 5.9900e+00, 6.7480e+01, 1.8620e+01,\n       1.8000e+01, 1.8030e+01, 1.1240e+01, 6.1250e+01, 4.2200e+00,\n       1.8000e+01, 2.1000e+01, 5.0000e+00, 8.0000e+00, 1.2500e+00,\n       3.6050e+01, 1.9282e+02, 4.2200e+00, 1.8000e+01, 5.6120e+01,\n       1.1340e+01, 1.8030e+01, 5.9900e+00, 1.4000e+01, 1.8000e+01,\n       1.0500e+02, 5.0000e+01, 1.5170e+01, 6.0000e+00, 5.3600e+00,\n       1.8000e+01, 3.6000e+01, 7.5050e+01, 6.1870e+01, 5.0000e+02,\n       1.5000e+01, 1.9560e+01, 1.0640e+01, 4.2200e+00, 1.6000e+01,\n       1.7000e+03, 1.5960e+01, 2.3950e+01, 7.9800e+00, 6.2700e+00,\n       2.5000e+01, 3.4100e+00, 3.0800e+01, 4.5000e+01, 1.8000e+01,\n       1.8330e+01, 4.9000e+01, 1.3600e+01, 4.1100e+00, 1.3000e+01,\n       1.9950e+01, 4.4115e+02, 8.0200e+01, 2.4000e+01, 2.0000e+00,\n       1.9000e+01, 8.2000e+02, 4.9900e+00, 2.5000e+01, 5.5000e+02,\n       4.2200e+00, 1.7000e+03, 2.0620e+01, 2.2620e+01, 5.8000e+01,\n       1.8030e+01, 2.0000e+01, 1.9990e+01, 5.9000e+00, 2.4300e+00,\n       4.2900e+01, 2.2500e+01, 4.8000e+00, 2.6000e+01, 7.4470e+01,\n       6.1870e+01, 4.0000e+00, 3.3170e+01, 4.2200e+00, 2.8080e+01,\n       5.0000e+00, 3.9910e+01, 3.3260e+01, 2.5000e+01, 1.5000e+01,\n       2.0000e+00, 3.2000e+01, 2.8000e+01, 1.8000e+03, 8.5000e+01,\n       2.9990e+01, 4.0000e+01, 2.5000e+01, 1.7000e+01, 1.3300e+01,\n       1.8000e+01, 8.3000e+02, 2.6000e+01, 8.0200e+00, 6.0000e+00,\n       3.9960e+01, 9.9900e+00, 4.0000e+01, 2.4500e+01, 2.0000e+02,\n       2.9000e+01, 1.9280e+01, 2.3000e+01, 7.5000e+02, 4.8700e+00,\n       1.8000e+01, 1.8000e+02, 1.6000e+01, 3.1365e+02, 1.8090e+01,\n       8.0000e+00, 2.4000e+01, 7.9100e+00, 1.5960e+01, 2.2550e+01,\n       8.2500e+00, 2.0000e+01, 1.8000e+01, 3.0000e+01, 4.2100e+00,\n       3.7500e+00, 2.0000e+01, 1.8000e+01, 5.0000e+02, 2.2550e+01,\n       5.7790e+01, 2.9408e+02, 6.0000e+00, 5.1880e+01, 8.0000e+00,\n       1.7000e+03, 3.1000e+01, 3.0000e+01, 1.9000e+01, 5.6000e+00,\n       7.0070e+01, 3.7700e+00, 1.8000e+01, 9.9950e+01, 2.9800e+00,\n       4.5830e+01, 1.8030e+01, 1.6000e+01, 2.5000e+01, 2.3400e+00,\n       1.8000e+01, 1.2638e+02, 4.9950e+01, 2.0000e+00, 1.0640e+01,\n       5.9000e+01, 2.1950e+01, 3.9990e+01, 8.6000e+01, 4.1100e+00,\n       1.4630e+01, 4.7890e+01, 1.0000e+01, 1.9900e+00, 1.8620e+01,\n       2.5000e+02, 8.2500e+00, 2.0000e+00, 4.0100e+01, 8.0200e+00,\n       8.2500e+00, 2.9900e+00]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m RidgeClassifier()\n\u001b[0;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:1444\u001b[0m, in \u001b[0;36mRidgeClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Ridge classifier model.\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m \n\u001b[1;32m   1424\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;124;03m        Instance of the estimator.\u001b[39;00m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1444\u001b[0m     X, y, sample_weight, Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_data(X, y, sample_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver)\n\u001b[1;32m   1446\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m   1447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:1188\u001b[0m, in \u001b[0;36m_RidgeClassifierMixin._prepare_data\u001b[0;34m(self, X, y, sample_weight, solver)\u001b[0m\n\u001b[1;32m   1179\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1180\u001b[0m     X,\n\u001b[1;32m   1181\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_binarizer \u001b[38;5;241m=\u001b[39m LabelBinarizer(pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, neg_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1188\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_binarizer\u001b[38;5;241m.\u001b[39mfit_transform(y)\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_binarizer\u001b[38;5;241m.\u001b[39my_type_\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1190\u001b[0m     y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:329\u001b[0m, in \u001b[0;36mLabelBinarizer.fit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[1;32m    310\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit label binarizer/transform multi-class labels to binary labels.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    The output of transform is sometimes referred to as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m        will be of CSR format.\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(y)\u001b[38;5;241m.\u001b[39mtransform(y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:306\u001b[0m, in \u001b[0;36mLabelBinarizer.fit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my has 0 samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y)\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_input_ \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39missparse(y)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m unique_labels(y)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/multiclass.py:104\u001b[0m, in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    102\u001b[0m _unique_labels \u001b[38;5;241m=\u001b[39m _FN_UNIQUE_LABELS\u001b[38;5;241m.\u001b[39mget(label_type, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _unique_labels:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mrepr\u001b[39m(ys))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_array_api_compliant:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# array_api does not allow for mixed dtypes\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     unique_ys \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mconcat([_unique_labels(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys])\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([3.0000e+01, 1.9800e+01, 1.0000e+00, 1.0640e+01, 1.1000e+02,\n       2.1000e+01, 2.9500e+00, 2.4060e+01, 2.0000e+00, 4.0800e+00,\n       1.0000e+02, 2.2000e+01, 8.0000e+01, 9.9800e+00, 6.0000e+00,\n       5.7310e+01, 4.5000e+00, 4.9500e+02, 3.5518e+02, 2.5000e+01,\n       1.9000e+01, 1.0243e+02, 8.2000e+01, 7.9750e+01, 4.8000e+00,\n       7.9800e+00, 1.0640e+01, 5.9000e+01, 1.3500e+02, 1.6500e+01,\n       8.0200e+00, 2.4000e+01, 2.8080e+01, 4.2200e+00, 1.0310e+01,\n       4.2200e+00, 5.7200e+00, 8.9400e+00, 3.2500e+02, 2.4000e+01,\n       2.7410e+01, 5.6940e+01, 2.9930e+01, 4.8000e+00, 3.6000e+02,\n       1.8330e+01, 4.6600e+00, 4.1100e+00, 3.4600e+00, 2.2500e+01,\n       4.7900e+00, 2.2000e+02, 8.9100e+00, 1.8000e+01, 8.0000e+00,\n       2.2550e+01, 3.0000e+01, 1.5960e+01, 1.0510e+01, 1.7190e+01,\n       1.0540e+01, 2.2500e+01, 5.2720e+01, 2.6610e+01, 5.8000e+00,\n       1.8000e-01, 2.7000e+01, 2.6610e+01, 1.7000e+01, 3.1930e+01,\n       3.1930e+01, 1.0000e+02, 3.0000e+01, 3.0000e+01, 1.2000e+02,\n       8.2500e+00, 2.7000e+01, 2.9500e+01, 6.2700e+00, 1.9000e+01,\n       1.4300e+02, 1.4220e+02, 4.2000e+00, 4.2000e+00, 4.2200e+00,\n       3.0000e+01, 6.5000e+01, 7.5000e+01, 8.1000e+01, 5.4000e+01,\n       1.5000e+02, 2.1550e+01, 9.8100e+01, 4.2890e+01, 1.8000e+03,\n       7.0000e+02, 1.3250e+01, 5.3210e+01, 9.6410e+02, 3.4190e+01,\n       2.2550e+01, 3.7250e+01, 6.0000e+00, 1.9955e+02, 3.0000e+01,\n       4.9950e+01, 5.0060e+01, 5.7300e+00, 3.0000e+01, 8.0200e+00,\n       3.5110e+01, 9.2400e+00, 6.0000e+00, 5.5000e+01, 8.0200e+00,\n       1.3137e+02, 1.4000e+01, 2.9900e+00, 1.1340e+01, 2.5000e+01,\n       2.6610e+01, 2.5000e+01, 8.5000e+01, 4.0490e+01, 2.2500e+01,\n       8.2500e+00, 5.5700e+00, 4.9950e+01, 8.2500e+00, 3.4370e+01,\n       1.0500e+02, 3.4000e+01, 1.5000e+00, 6.9000e+01, 2.1550e+01,\n       4.0490e+01, 9.7400e+00, 4.6530e+01, 1.3600e+01, 2.2550e+01,\n       1.5000e+01, 2.5000e+01, 2.0620e+01, 5.8000e+01, 2.3000e+01,\n       1.0630e+01, 2.5280e+01, 1.5300e+02, 1.1970e+01, 1.1970e+01,\n       2.5000e+01, 3.4950e+01, 1.9602e+02, 5.5000e+01, 3.1930e+01,\n       4.5000e+01, 1.5680e+01, 2.0000e+00, 2.5000e+01, 1.5000e+01,\n       4.6500e+01, 5.0000e+00, 2.8080e+01, 6.8700e+00, 1.0460e+01,\n       3.6000e+01, 5.3200e+00, 1.9500e+01, 9.8000e+01, 3.2000e-01,\n       2.6000e+01, 9.9900e+00, 1.2000e+03, 3.2000e+01, 3.4000e+01,\n       4.0000e+01, 3.0000e+02, 1.0000e+00, 1.3300e+01, 2.5420e+01,\n       3.9022e+02, 3.0000e+01, 1.5000e+01, 1.0510e+01, 1.3000e+01,\n       8.0000e+00, 2.1290e+01, 6.8700e+00, 6.0000e+00, 6.2700e+00,\n       1.8000e+01, 4.8100e+00, 1.1000e+02, 1.3600e+01, 5.5000e+01,\n       2.0620e+01, 4.5000e+01, 2.2500e+02, 4.1100e+00, 3.0000e+01,\n       4.1250e+01, 1.0500e+02, 1.9000e+01, 8.0200e+00, 4.2200e+00,\n       4.9900e+00, 5.3210e+01, 9.0000e-01, 5.1220e+01, 2.8080e+01,\n       6.0000e+02, 2.9320e+01, 5.9900e+00, 5.9100e+00, 1.7160e+01,\n       3.3260e+01, 4.3200e+00, 3.9000e+00, 3.0000e+01, 1.0500e+02,\n       3.8730e+01, 5.5000e+01, 7.8000e+01, 1.0000e+01, 7.9500e+00,\n       3.0000e+01, 1.1970e+01, 3.7570e+01, 1.1999e+02, 2.2100e+02,\n       1.9950e+01, 8.0000e+00, 6.0000e+01, 2.7910e+01, 1.0040e+01,\n       2.0000e+00, 4.2200e+00, 3.0000e+02, 1.5000e+01, 1.8000e+01,\n       6.0000e+00, 2.1550e+01, 1.5000e+01, 7.0000e+02, 8.9400e+00,\n       6.0000e+00, 3.4000e+01, 3.2930e+01, 1.8620e+01, 1.0000e+01,\n       2.5950e+01, 5.4900e+00, 1.6000e+01, 9.4900e+00, 5.6700e+00,\n       4.4980e+01, 6.0000e+00, 1.0950e+01, 5.5000e+01, 4.2200e+00,\n       1.5000e+02, 4.2200e+00, 2.9500e+00, 1.9000e+01, 3.2070e+01,\n       8.0000e+00, 1.8000e+01, 5.3600e+00, 1.6500e+01, 1.8000e+01,\n       4.8800e+00, 1.6500e+02, 5.2720e+01, 2.0000e+01, 1.6870e+01,\n       7.9900e+00, 5.5000e+01, 3.8000e+01, 8.0200e+00, 1.9950e+01,\n       3.9000e+01, 5.4900e+00, 1.5000e+00, 8.7300e+00, 4.8000e+01,\n       1.8030e+01, 1.9950e+01, 1.6960e+01, 4.3500e+02, 1.0000e+01,\n       4.2200e+00, 6.0000e+00, 3.4000e+01, 2.1550e+01, 8.2500e+00,\n       3.5000e+01, 2.1220e+01, 5.1880e+01, 6.1870e+01, 1.5950e+01,\n       4.7800e+02, 2.4000e+01, 4.9950e+01, 4.6560e+01, 1.8000e+03,\n       3.3230e+01, 6.0000e+02, 2.0000e+01, 2.4000e+01, 1.2500e+00,\n       1.5960e+01, 2.6610e+01, 2.0000e+00, 5.8000e+00, 3.5140e+01,\n       8.0000e+00, 2.6000e+01, 1.1970e+01, 8.0000e+00, 4.2200e+00,\n       3.8000e+01, 1.8000e+01, 1.0640e+01, 1.8330e+01, 4.5000e+01,\n       8.0000e+00, 1.8000e+03, 1.9990e+01, 1.5000e+01, 1.4000e+01,\n       2.0000e+00, 1.7000e+01, 7.2000e+00, 2.0000e+00, 4.9200e+00,\n       4.2200e+00, 3.4600e+00, 8.9400e+00, 3.6000e+01, 3.0000e+01,\n       2.8000e+01, 2.3400e+00, 4.9900e+00, 9.3000e+01, 2.2000e+01,\n       2.2550e+01, 4.0000e+01, 7.1500e+01, 2.9000e+00, 2.3300e+00,\n       2.9700e+00, 2.0000e+01, 2.7500e+01, 3.3260e+01, 6.8970e+01,\n       2.3000e+01, 1.6000e+02, 1.5000e+00, 5.8000e+00, 4.8200e+01,\n       8.5000e+01, 2.8000e+01, 4.0000e+01, 1.8000e+03, 1.7190e+01,\n       4.9900e+00, 2.1000e+02, 1.8000e+02, 2.8990e+01, 1.3000e+02,\n       6.9900e+00, 8.0200e+01, 6.1900e+00, 3.0000e+01, 1.4300e+02,\n       1.0000e+02, 1.8000e+03, 4.9500e+01, 1.1300e+01, 3.5000e+01,\n       3.4000e+01, 2.3000e+01, 1.8000e+01, 2.0000e+00, 1.3600e+01,\n       1.4000e+01, 1.2000e+01, 3.0000e+01, 3.9200e+01, 5.5884e+02,\n       3.5250e+01, 4.5000e+01, 5.4500e+00, 1.0640e+01, 2.6610e+01,\n       1.8030e+01, 3.5000e+01, 5.2700e+01, 4.0000e+00, 3.3260e+01,\n       3.9990e+01, 1.9000e+01, 1.8000e+01, 7.2000e+01, 2.4610e+01,\n       7.9750e+01, 2.7000e+00, 2.5000e+01, 5.0000e+00, 3.8700e+00,\n       2.1220e+01, 1.2130e+01, 4.9390e+01, 1.0640e+01, 5.2300e+00,\n       1.9000e+01, 1.9000e+01, 3.2300e+01, 2.9400e+01, 2.0000e+01,\n       5.7310e+01, 1.0500e+02, 1.3600e+01, 5.0000e+00, 2.6610e+01,\n       7.9750e+01, 3.3230e+01, 2.5000e+01, 6.6900e+00, 5.2000e+01,\n       5.9000e+01, 4.0000e+01, 3.3260e+01, 3.7200e+00, 3.2000e-01,\n       6.0000e+01, 8.9500e+00, 7.9100e+00, 2.8000e+01, 4.5000e+01,\n       2.4990e+01, 1.0505e+02, 2.2500e+00, 4.7760e+01, 1.6230e+01,\n       3.3230e+01, 2.2900e+00, 4.2570e+01, 4.2200e+00, 2.2610e+01,\n       4.6000e+01, 1.2470e+01, 5.7300e+00, 3.2000e-01, 1.0641e+02,\n       3.9990e+01, 1.6000e+01, 5.8000e+00, 8.0250e+01, 2.0250e+01,\n       1.0000e+01, 2.1000e+01, 1.2000e+01, 1.7600e+01, 1.6500e+01,\n       2.3940e+01, 2.3000e+01, 2.0000e+00, 4.9900e+00, 5.0000e+00,\n       1.6480e+01, 5.2720e+01, 8.0000e+00, 1.5000e+01, 5.6140e+01,\n       3.6660e+01, 2.1550e+01, 3.2000e+01, 4.2200e+00, 5.6140e+01,\n       6.1250e+01, 6.5000e+01, 1.9990e+01, 3.2000e+01, 1.6000e+03,\n       1.1369e+02, 1.7960e+01, 9.6000e+01, 2.1500e+01, 5.3200e+00,\n       6.0000e+00, 3.9910e+01, 4.0000e+00, 2.3400e+00, 8.0000e+00,\n       1.0000e+00, 2.2620e+01, 8.2490e+01, 1.0000e+00, 1.7150e+01,\n       5.0000e+01, 7.0000e+00, 3.3260e+01, 4.5000e+01, 1.6000e+01,\n       3.2000e+01, 5.8500e+02, 3.3230e+01, 4.9950e+01, 3.5400e+00,\n       1.8000e+01, 5.3200e+00, 5.5000e+01, 2.2610e+01, 2.1550e+01,\n       1.0000e+01, 1.4450e+01, 2.7940e+01, 1.9950e+01, 4.1100e+00,\n       2.6610e+01, 3.8250e+01, 5.0000e+00, 1.6000e+01, 2.3000e+01,\n       1.0640e+01, 2.5000e+01, 1.5000e+02, 2.6610e+01, 2.0620e+01,\n       9.4900e+00, 1.7000e+03, 2.8990e+01, 8.5000e+01, 2.4610e+01,\n       3.4230e+01, 4.2200e+00, 1.3000e+01, 7.7300e+00, 1.8000e+01,\n       6.0000e+00, 1.9000e+01, 2.0000e+00, 1.5990e+01, 3.3112e+02,\n       7.9800e+00, 4.8000e+01, 2.2620e+01, 2.2500e+00, 1.5300e+02,\n       2.5000e+01, 9.9770e+01, 1.4630e+01, 2.3280e+01, 1.1760e+01,\n       2.0000e+01, 3.3260e+01, 1.7000e+03, 6.5000e+02, 3.7570e+01,\n       3.0900e+00, 4.2200e+00, 5.9900e+00, 6.7480e+01, 1.8620e+01,\n       1.8000e+01, 1.8030e+01, 1.1240e+01, 6.1250e+01, 4.2200e+00,\n       1.8000e+01, 2.1000e+01, 5.0000e+00, 8.0000e+00, 1.2500e+00,\n       3.6050e+01, 1.9282e+02, 4.2200e+00, 1.8000e+01, 5.6120e+01,\n       1.1340e+01, 1.8030e+01, 5.9900e+00, 1.4000e+01, 1.8000e+01,\n       1.0500e+02, 5.0000e+01, 1.5170e+01, 6.0000e+00, 5.3600e+00,\n       1.8000e+01, 3.6000e+01, 7.5050e+01, 6.1870e+01, 5.0000e+02,\n       1.5000e+01, 1.9560e+01, 1.0640e+01, 4.2200e+00, 1.6000e+01,\n       1.7000e+03, 1.5960e+01, 2.3950e+01, 7.9800e+00, 6.2700e+00,\n       2.5000e+01, 3.4100e+00, 3.0800e+01, 4.5000e+01, 1.8000e+01,\n       1.8330e+01, 4.9000e+01, 1.3600e+01, 4.1100e+00, 1.3000e+01,\n       1.9950e+01, 4.4115e+02, 8.0200e+01, 2.4000e+01, 2.0000e+00,\n       1.9000e+01, 8.2000e+02, 4.9900e+00, 2.5000e+01, 5.5000e+02,\n       4.2200e+00, 1.7000e+03, 2.0620e+01, 2.2620e+01, 5.8000e+01,\n       1.8030e+01, 2.0000e+01, 1.9990e+01, 5.9000e+00, 2.4300e+00,\n       4.2900e+01, 2.2500e+01, 4.8000e+00, 2.6000e+01, 7.4470e+01,\n       6.1870e+01, 4.0000e+00, 3.3170e+01, 4.2200e+00, 2.8080e+01,\n       5.0000e+00, 3.9910e+01, 3.3260e+01, 2.5000e+01, 1.5000e+01,\n       2.0000e+00, 3.2000e+01, 2.8000e+01, 1.8000e+03, 8.5000e+01,\n       2.9990e+01, 4.0000e+01, 2.5000e+01, 1.7000e+01, 1.3300e+01,\n       1.8000e+01, 8.3000e+02, 2.6000e+01, 8.0200e+00, 6.0000e+00,\n       3.9960e+01, 9.9900e+00, 4.0000e+01, 2.4500e+01, 2.0000e+02,\n       2.9000e+01, 1.9280e+01, 2.3000e+01, 7.5000e+02, 4.8700e+00,\n       1.8000e+01, 1.8000e+02, 1.6000e+01, 3.1365e+02, 1.8090e+01,\n       8.0000e+00, 2.4000e+01, 7.9100e+00, 1.5960e+01, 2.2550e+01,\n       8.2500e+00, 2.0000e+01, 1.8000e+01, 3.0000e+01, 4.2100e+00,\n       3.7500e+00, 2.0000e+01, 1.8000e+01, 5.0000e+02, 2.2550e+01,\n       5.7790e+01, 2.9408e+02, 6.0000e+00, 5.1880e+01, 8.0000e+00,\n       1.7000e+03, 3.1000e+01, 3.0000e+01, 1.9000e+01, 5.6000e+00,\n       7.0070e+01, 3.7700e+00, 1.8000e+01, 9.9950e+01, 2.9800e+00,\n       4.5830e+01, 1.8030e+01, 1.6000e+01, 2.5000e+01, 2.3400e+00,\n       1.8000e+01, 1.2638e+02, 4.9950e+01, 2.0000e+00, 1.0640e+01,\n       5.9000e+01, 2.1950e+01, 3.9990e+01, 8.6000e+01, 4.1100e+00,\n       1.4630e+01, 4.7890e+01, 1.0000e+01, 1.9900e+00, 1.8620e+01,\n       2.5000e+02, 8.2500e+00, 2.0000e+00, 4.0100e+01, 8.0200e+00,\n       8.2500e+00, 2.9900e+00]),)"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier \n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "model = RidgeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(xtest)\n",
    "\n",
    "# # Calculate Classification metrics\n",
    "# accuracy = accuracy_score(ytest, y_pred)\n",
    "# precision = precision_score(ytest, y_pred, average='weighted')\n",
    "# recall = recall_score(ytest, y_pred, average='weighted')\n",
    "# f1 = f1_score(ytest, y_pred, average='weighted')\n",
    "# print(f\"RidgeClassifier model scores Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
    "\n",
    "# confusion_matrix(ytest, y_pred, labels = [1,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
